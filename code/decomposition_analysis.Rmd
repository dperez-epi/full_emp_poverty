---
title: "composition analysis"
author: "Daniel Perez"
date: "04/08/2022"
output: html_document
---

```{r libraries, include=FALSE}
library(tidyverse)
library(epiextractr)
library(epidatatools)
library(labelled)
library(here)
library(blsAPI)
library(openxlsx)
library(MetricsWeighted)
library(gtools)
library(statar)
library(realtalk)
```


```{r Load CPS}
#Load CPI data
cpi <- cpi_u_rs_annual
cpi_2019 <- annual_cpi$cpi_u_rs[annual_cpi$year=='2019']


#Create CPS data frame. 
cps <- load_org(1994:2019, year, month, orgwgt, age, emp, lfstat, selfemp, selfinc, hoursu1, hoursu1i, hoursvary, paidhre, wage, wageotc, weekpay, mind16, mocc10) %>%
  filter(age>=16, emp %in% c(0,1)) %>%
  mutate(wgt = orgwgt/12) %>% 
  #create new version of selfemp/selfinc to exclude self employer workers
  mutate(selfemp0 = ifelse(selfemp==1 & !is.na(selfemp), yes=1, no=0),
         selfinc0 = ifelse(selfinc==1 & !is.na(selfinc), yes=1, no=0),
         paidhre = ifelse(paidhre==1 & !is.na(paidhre), yes=1, no=0)) %>%
  filter(selfemp0==0, selfinc0==0) %>%
  #Merge CPI-U-RS data and inflation adjust wages to 2019$
  left_join(cpi, by='year') %>% 
  mutate(hours = hoursu1i) %>% 
  mutate(realwage = wage*(cpi_2019/cpi_u_rs),
         #Construct our weekly pay variable, realweekpay_c
         # Note: if hours are positive, then multiply hours x realwage. Otherwise assign realweekpay_c == NA
         realweekpay_c = ifelse(hours>0, yes=hours * realwage, NA)) %>% 
         #create indicators for whether an individual has positive work hours, weekly pay, and/or wages
  mutate(pwages = ifelse(realwage>0 & !is.na(realwage) , yes=1, no=0), 
         pweekpay.c = ifelse(realweekpay_c>0 & !is.na(realweekpay_c) , yes=1, no=0),
         phours1 = ifelse(hours>0 & !is.na(hours), yes=1, no=0)) %>%
  #Set labels for indicators using labelled package
  set_value_labels(pwages = c('Positive wages' = 1, 'Zero wages' = 0),
                   pweekpay.c = c('Positive constr. weekpay' = 1, 'Zero constr. weekpay' = 0),
                   phours1 = c('Positive hours, primary job' = 1, 'Zero hours' =0))

```

As a note, we want to remove self employed / self incorporated folks because they do not report wages / hours despite being employed. We do want to keep non-self emp/inc folks though, including those who are just NILF or selfemp/selfinc==NA, because we want to turn them into NILF workers with zero wages/hours

```{r Quintiles and Median analysis}

#Set seed for reproducible results
set.seed(1017)

filteredcps <- cps %>% 
  filter(age<65, selfemp0==0, selfinc0==0) %>% 
  #Keep workers who are either employed with positive hours/wages, or unemployed with zero hours/wages. No other combinations.
  filter((emp==1 & pwages==1 & phours1==1) | (emp==0 & pwages==0 & phours1==0)) %>% 
  #create two hours variables. One where unemploye
  mutate(hours0 = replace(hours, emp==0, 0),
         hours_na = replace(hours, emp==0, NA)) %>%
  #assign each observation a uniformly distributed random # between 0 and 1
  mutate(index = runif(nrow(.), min = 0, max=1)) %>%  
  #Arrange our observations according to year + real weekly pay
  arrange(year, !is.na(realweekpay_c), realweekpay_c, index) %>%
  group_by(year) %>% 
  #Create a column that is the cumulative sum of the org weight, 
  #so we can split our dataframe up into equal parts according to the weighted
  #population
  mutate(cumsum = cumsum(orgwgt/12), 
         #column with total pop in each year
         pop = sum(orgwgt/12), 
         # 1/5th of the weighted population by year
         quint_pop = pop/5,
         # 1/2 of weighted pop by year
         med_pop = pop/2) %>% 
  #Assign our arranged sample to quintiles
  mutate(quint_bins = ifelse(cumsum <= quint_pop, 1,
                       ifelse(cumsum > quint_pop & cumsum <= quint_pop*2, 2,
                              ifelse(cumsum > quint_pop*2 & cumsum <= quint_pop*3, 3,
                                     ifelse(cumsum > quint_pop*3 & cumsum <= quint_pop*4, 4, 5))))) %>%
  #Same as above, but instead there are two bins - the top/bottom 50%
  mutate(med_bins = ifelse(cumsum <= med_pop, yes=1, no=2)) %>% 
  ungroup()

#Create decomposition analysis by quintiles
quintile_metrics <- filteredcps %>%
  group_by(year, quint_bins) %>%
  summarize(avg_weekpay = weighted.mean(realweekpay_c, na.rm=TRUE),
            epop = weighted.mean(emp, w=wgt, na.rm=TRUE),
            avg_hours = weighted.mean(hours0, w=wgt, na.rm=TRUE),
            avg_hours_na = weighted.mean(hours_na, w=wgt, na.rm=TRUE),
            avg_wage = weighted.mean(realwage, w=wgt, na.rm=TRUE),
            n = n(),
            wgt_n = sum(orgwgt/12)) %>% 
  pivot_wider(id_cols = year, names_from = quint_bins, values_from = c(avg_wage, avg_hours, avg_hours_na, avg_weekpay, epop, n, wgt_n))

#Create decomposition analysis of bottom/top 50%
median_metrics <- filteredcps %>% 
  group_by(year, med_bins) %>% 
  summarize(avg_weekpay = weighted.mean(realweekpay_c, na.rm=TRUE),
            epop = weighted.mean(emp, w=wgt, na.rm=TRUE),
            avg_hours = weighted.mean(hours0, w=wgt, na.rm=TRUE),
            avg_hours_na = weighted.mean(hours_na, w=wgt, na.rm=TRUE),
            avg_wage = weighted.mean(realwage, w=wgt, na.rm=TRUE),
            n = n(),
            wgt_n = sum(orgwgt/12)) %>% 
  pivot_wider(id_cols = year, names_from = med_bins, values_from = c(avg_wage, avg_hours, avg_hours_na, avg_weekpay, epop, n, wgt_n))


#determines cutoff values of avg weekly pay for each quintile 
quint_cutoffs <- filteredcps %>%
  group_by(year, quint_bins) %>%
  summarize(avg_weekpay_cutoff = max(realweekpay_c)) %>%
  pivot_wider(id_cols = year, names_from = quint_bins, values_from = avg_weekpay_cutoff)

#determines cutoff values of avg weekly pay for bottom and top 50% 
med_cutoffs <- filteredcps %>% 
  group_by(year, med_bins) %>% 
  summarize(avg_weekpay_cutoff = max(realweekpay_c, na.rm=TRUE)) %>% 
  pivot_wider(id_cols = year, names_from = med_bins, values_from = avg_weekpay_cutoff)

```
This chunk can be ignored. It was solely for benchmarking purposes.

```{r Epop benchmark}

epops25_54 <- cps %>% 
  filter(age>=25 & age <=54) %>% 
  group_by(year) %>% 
  summarise(epop25_54 = weighted.mean(emp, w=orgwgt/12, na.rm=TRUE))

epop_16plus_byemp <- cps %>% 
  filter(age>=16, emp %in% c(0,1)) %>% 
  group_by(year) %>% 
  summarise(epop16plus_byemp = weighted.mean(emp, w=orgwgt/12, na.rm=TRUE))

epop_16plus_emp_noself <- cps %>% 
  filter(age>=16, emp %in% c(0,1)) %>% 
  filter(selfemp0==0, selfinc0==0) %>% 
  group_by(year) %>% 
  summarise(epop_16plus_emp_noself = weighted.mean(emp, w=orgwgt/12, na.rm=TRUE))

epop_under65_byemp_noself <-cps %>% 
  filter(age<65) %>% 
  group_by(year) %>% 
  summarise(epop_under65_byemp_noself = weighted.mean(emp, w=orgwgt/12, na.rm=TRUE))

epop_under65_nocombo <- filteredcps %>% 
  group_by(year) %>% 
  summarise(epop_under65_nocombo = weighted.mean(emp, w=orgwgt/12, na.rm=TRUE))
      
epops_16plus <- cps %>% 
  filter(age>=16) %>% 
  group_by(year) %>% 
  summarise(epop_16plus = weighted.mean(emp, w=orgwgt/12, na.rm=TRUE)) %>% 
  left_join(epops25_54) %>%
  left_join(epop_16plus_byemp) %>% 
  left_join(epop_16plus_emp_noself)# %>% 
  # write_csv(here('output/epop_benchmark_under65.csv'), col_names = TRUE)

```

This chunk analyzes the observations we drop from the "filteredcps" dataframe

```{r Dropped sample analysis}
dropped_sample <- cps %>% 
  filter(age<65, selfemp0==0, selfinc0==0) %>% 
  filter(!((emp==1 & pwages==1 & phours1==1) | (emp==0 & pwages==0 & phours1==0))) %>% 
  group_by(year) %>% 
  summarize(dropped_n = n()) %>% 
  mutate(dropped_freq = dropped_n/sum(dropped_n))


remaining_samp <- cps %>% 
  filter(age<65, selfemp0==0, selfinc0==0) %>% 
  filter((emp==1 & pwages==1 & phours1==1) | (emp==0 & pwages==0 & phours1==0)) %>% 
  mutate(realwage0 = replace(realwage, emp==0, -999),
         realweekpay0 = replace(realweekpay_c, emp==0, -999),
         hours0 = replace(hours, emp==0, 0)) %>% 
  group_by(year) %>% 
  summarize(remaining_n = n()) %>% 
  mutate(remaining_freq = remaining_n/sum(remaining_n)) %>% 
  left_join(dropped_sample)# %>% 
  # write_csv(here('output/sample.csv'))

```


```{r Workbook export}

rand_order <- createWorkbook()

pct = createStyle(numFmt = '0.0%')
acct = createStyle(numFmt = '#,#0.0')
currency = createStyle(numFmt = '$#,#0.00') 
hs2 <- createStyle(fgFill = "#bfbfbf", halign = "CENTER", textDecoration = "Bold",
                   border = "Bottom", fontColour = "black")

#addWorksheet(rand_order, sheetName = "Quintile metrics")
addWorksheet(rand_order, sheetName = "Median metrics")
# addWorksheet(rand_order, sheetName = "Quint cutoffs")
addWorksheet(rand_order, sheetName = "Median cutoffs")


# writeData(rand_order, quintile_metrics, headerStyle = hs2, sheet = "Quintile metrics", startCol = 1, startRow = 1, colNames = TRUE)
writeData(rand_order, median_metrics, headerStyle = hs2, sheet = "Median metrics", startCol = 1, startRow = 1, colNames = TRUE)
# writeData(rand_order, quint_cutoffs, headerStyle = hs2, sheet = "Quint cutoffs", startCol = 1, startRow = 1, colNames = TRUE)
writeData(rand_order, med_cutoffs, headerStyle = hs2, sheet = "Median cutoffs", startCol = 1, startRow = 1, colNames = TRUE)

#Currency format
#addStyle(rand_order, "Quintile metrics", style=currency, cols=c(2:27,80:105), rows=2:(nrow(quintile_metrics)+1), gridExpand=TRUE)
#addStyle(rand_order, "Median metrics", style=currency, cols=c(2:27,80:105), rows=2:(nrow(median_metrics)+1), gridExpand=TRUE)

#Percent format
# addStyle(rand_order, "Quintile metrics", style=pct, cols=c(28:53), rows=2:(nrow(quintile_metrics)+1), gridExpand=TRUE)
# addStyle(rand_order, "Median metrics", style=pct, cols=c(28:53), rows=2:(nrow(median_metrics)+1), gridExpand=TRUE)

# accounting format
# addStyle(rand_order, "Quintile metrics", style=acct, cols=c(54:79,106:157), rows=2:(nrow(quintile_metrics)+1), gridExpand=TRUE)
# addStyle(rand_order, "Median metrics", style=acct, cols=c(54:79,106:157), rows=2:(nrow(median_metrics)+1), gridExpand=TRUE)

saveWorkbook(rand_order, here(paste0("output/decomposition_analysis", format(Sys.time(), "%d-%b-%Y %H.%M"), ".xlsx")))
```
